<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Accord.MachineLearning.GPL</name>
    </assembly>
    <members>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression">
            <summary>
              Sequential Minimal Optimization (SMO) Algorithm for Regression. Warning:
              this code is contained in a GPL assembly. Thus, if you link against this
              assembly, you should comply with the GPL license.
            </summary>
            
            <remarks>
            <para>
              The SMO algorithm is an algorithm for solving large quadratic programming (QP)
              optimization problems, widely used for the training of support vector machines.
              First developed by John C. Platt in 1998, SMO breaks up large QP problems into
              a series of smallest possible QP problems, which are then solved analytically.</para>
            <para>
              This class incorporates modifications in the original SMO algorithm to solve
              regression problems as suggested by Alex J. Smola and Bernhard Schölkopf and
              further modifications for better performance by Shevade et al.</para> 
              
            <para>
              Portions of this implementation has been based on the GPL code by Sylvain Roy in SMOreg.java, a 
              part of the Weka software package. It is, thus, available under the same GPL license. This file is
              not linked against the rest of the Accord.NET Framework and can only be used in GPL applications.
              This class is only available in the special Accord.MachineLearning.GPL assembly, which has to be
              explicitly selected in the framework installation. Before linking against this assembly, please
              read the <a href="http://www.gnu.org/copyleft/gpl.html">GPL license</a> for more details. This
              assembly also should have been distributed with a copy of the GNU GPLv3 alongside with it.
            </para>
            
            <para>
              To use this class, add a reference to the <c>Accord.MachineLearning.GPL.dll</c> assembly
              that resides inside the Release/GPL folder of the framework's installation directory.</para>
              
            <para>
              References:
              <list type="bullet">
                <item><description>
                 A. J. Smola and B. Schölkopf. A Tutorial on Support Vector Regression. NeuroCOLT2
                 Technical Report Series, 1998. Available on: <a href="http://www.kernel-machines.org/publications/SmoSch98c">
                 http://www.kernel-machines.org/publications/SmoSch98c </a></description></item>
                <item><description>
                 S.K. Shevade et al. Improvements to SMO Algorithm for SVM Regression, 1999. Available
                 on: <a href="http://drona.csa.iisc.ernet.in/~chiru/papers/ieee_smo_reg.ps.gz">
                 http://drona.csa.iisc.ernet.in/~chiru/papers/ieee_smo_reg.ps.gz </a></description></item>
                <item><description>
                 G. W. Flake, S. Lawrence. Efficient SVM Regression Training with SMO.
                 Available on: <a href="http://www.keerthis.com/smoreg_ieee_shevade_00.pdf">
                 http://www.keerthis.com/smoreg_ieee_Shevade_00.pdf </a></description></item>
              </list></para>
            </remarks>
            
            <example>
            <code>
            // Example regression problem. Suppose we are trying
            // to model the following equation: f(x, y) = 2x + y
            
            double[][] inputs = // (x, y)
            {
                new double[] { 0,  1 }, // 2*0 + 1 =  1
                new double[] { 4,  3 }, // 2*4 + 3 = 11
                new double[] { 8, -8 }, // 2*8 - 8 =  8
                new double[] { 2,  2 }, // 2*2 + 2 =  6
                new double[] { 6,  1 }, // 2*6 + 1 = 13
                new double[] { 5,  4 }, // 2*5 + 4 = 14
                new double[] { 9,  1 }, // 2*9 + 1 = 19
                new double[] { 1,  6 }, // 2*1 + 6 =  8
            };
            
            double[] outputs = // f(x, y)
            {
                    1, 11, 8, 6, 13, 14, 20, 8
            };
            
            // Create Kernel Support Vector Machine with a Polynomial Kernel of 2nd degree
            var machine = new KernelSupportVectorMachine(new Polynomial(2), inputs: 2);
            
            // Create the sequential minimal optimization teacher
            var learn = new SequentialMinimalOptimizationRegression(machine, inputs, outputs);
            
            // Run the learning algorithm
            double error = learn.Run();
            
            // Compute the answer for one particular example
            double fxy = machine.Compute(inputs[0]); // 1.0003849827673186
            </code>
            </example>
            
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimizationRegression`3">
            <summary>
              Base class for Sequential Minimal Optimization for regression.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimizationRegression`3.#ctor">
            <summary>
              Initializes a new instance of a Sequential Minimal Optimization (SMO) algorithm.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimizationRegression`3.InnerRun">
            <summary>
            Runs the learning algorithm.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimizationRegression`3.examineExample(System.Int32)">
            <summary>
             Chooses which multipliers to optimize using heuristics.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimizationRegression`3.takeStep(System.Int32,System.Int32)">
            <summary>
              Analytically solves the optimization problem for two Lagrange multipliers.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimizationRegression`3.compute(`2)">
            <summary>
              Computes the SVM output for a given point.
            </summary>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimizationRegression`3.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{`2},`2[],System.Double[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="P:Accord.MachineLearning.VectorMachines.Learning.BaseSequentialMinimalOptimizationRegression`3.Tolerance">
            <summary>
              Convergence tolerance. Default value is 1e-3.
            </summary>
            <remarks>
              The criterion for completing the model training process. The default is 0.001.
            </remarks>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression"/> class.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.#ctor(Accord.MachineLearning.VectorMachines.ISupportVectorMachine{System.Double[]},System.Double[][],System.Double[])">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression.Create(System.Int32,Accord.Statistics.Kernels.IKernel{System.Double[]})">
            <summary>
              Obsolete.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression`1">
            <summary>
              Sequential Minimal Optimization (SMO) Algorithm for Regression. Warning:
              this code is contained in a GPL assembly. Thus, if you link against this
              assembly, you should comply with the GPL license.
            </summary>
            
            <remarks>
            <para>
              The SMO algorithm is an algorithm for solving large quadratic programming (QP)
              optimization problems, widely used for the training of support vector machines.
              First developed by John C. Platt in 1998, SMO breaks up large QP problems into
              a series of smallest possible QP problems, which are then solved analytically.</para>
            <para>
              This class incorporates modifications in the original SMO algorithm to solve
              regression problems as suggested by Alex J. Smola and Bernhard Schölkopf and
              further modifications for better performance by Shevade et al.</para> 
              
            <para>
              Portions of this implementation has been based on the GPL code by Sylvain Roy in SMOreg.java, a 
              part of the Weka software package. It is, thus, available under the same GPL license. This file is
              not linked against the rest of the Accord.NET Framework and can only be used in GPL applications.
              This class is only available in the special Accord.MachineLearning.GPL assembly, which has to be
              explicitly selected in the framework installation. Before linking against this assembly, please
              read the <a href="http://www.gnu.org/copyleft/gpl.html">GPL license</a> for more details. This
              assembly also should have been distributed with a copy of the GNU GPLv3 alongside with it.
            </para>
            
            <para>
              To use this class, add a reference to the <c>Accord.MachineLearning.GPL.dll</c> assembly
              that resides inside the Release/GPL folder of the framework's installation directory.</para>
              
            <para>
              References:
              <list type="bullet">
                <item><description>
                 A. J. Smola and B. Schölkopf. A Tutorial on Support Vector Regression. NeuroCOLT2
                 Technical Report Series, 1998. Available on: <a href="http://www.kernel-machines.org/publications/SmoSch98c">
                 http://www.kernel-machines.org/publications/SmoSch98c </a></description></item>
                <item><description>
                 S.K. Shevade et al. Improvements to SMO Algorithm for SVM Regression, 1999. Available
                 on: <a href="http://drona.csa.iisc.ernet.in/~chiru/papers/ieee_smo_reg.ps.gz">
                 http://drona.csa.iisc.ernet.in/~chiru/papers/ieee_smo_reg.ps.gz </a></description></item>
                <item><description>
                 G. W. Flake, S. Lawrence. Efficient SVM Regression Training with SMO.
                 Available on: <a href="http://www.keerthis.com/smoreg_ieee_shevade_00.pdf">
                 http://www.keerthis.com/smoreg_ieee_Shevade_00.pdf </a></description></item>
              </list></para>
            </remarks>
            
            <example>
            <code>
            // Example regression problem. Suppose we are trying
            // to model the following equation: f(x, y) = 2x + y
            
            double[][] inputs = // (x, y)
            {
                new double[] { 0,  1 }, // 2*0 + 1 =  1
                new double[] { 4,  3 }, // 2*4 + 3 = 11
                new double[] { 8, -8 }, // 2*8 - 8 =  8
                new double[] { 2,  2 }, // 2*2 + 2 =  6
                new double[] { 6,  1 }, // 2*6 + 1 = 13
                new double[] { 5,  4 }, // 2*5 + 4 = 14
                new double[] { 9,  1 }, // 2*9 + 1 = 19
                new double[] { 1,  6 }, // 2*1 + 6 =  8
            };
            
            double[] outputs = // f(x, y)
            {
                    1, 11, 8, 6, 13, 14, 20, 8
            };
            
            // Create Kernel Support Vector Machine with a Polynomial Kernel of 2nd degree
            var machine = new KernelSupportVectorMachine(new Polynomial(2), inputs: 2);
            
            // Create the sequential minimal optimization teacher
            var learn = new SequentialMinimalOptimizationRegression(machine, inputs, outputs);
            
            // Run the learning algorithm
            double error = learn.Run();
            
            // Compute the answer for one particular example
            double fxy = machine.Compute(inputs[0]); // 1.0003849827673186
            </code>
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression`1.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
        <member name="T:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression`2">
            <summary>
              Sequential Minimal Optimization (SMO) Algorithm for Regression. Warning:
              this code is contained in a GPL assembly. Thus, if you link against this
              assembly, you should comply with the GPL license.
            </summary>
            
            <remarks>
            <para>
              The SMO algorithm is an algorithm for solving large quadratic programming (QP)
              optimization problems, widely used for the training of support vector machines.
              First developed by John C. Platt in 1998, SMO breaks up large QP problems into
              a series of smallest possible QP problems, which are then solved analytically.</para>
            <para>
              This class incorporates modifications in the original SMO algorithm to solve
              regression problems as suggested by Alex J. Smola and Bernhard Schölkopf and
              further modifications for better performance by Shevade et al.</para> 
              
            <para>
              Portions of this implementation has been based on the GPL code by Sylvain Roy in SMOreg.java, a 
              part of the Weka software package. It is, thus, available under the same GPL license. This file is
              not linked against the rest of the Accord.NET Framework and can only be used in GPL applications.
              This class is only available in the special Accord.MachineLearning.GPL assembly, which has to be
              explicitly selected in the framework installation. Before linking against this assembly, please
              read the <a href="http://www.gnu.org/copyleft/gpl.html">GPL license</a> for more details. This
              assembly also should have been distributed with a copy of the GNU GPLv3 alongside with it.
            </para>
            
            <para>
              To use this class, add a reference to the <c>Accord.MachineLearning.GPL.dll</c> assembly
              that resides inside the Release/GPL folder of the framework's installation directory.</para>
              
            <para>
              References:
              <list type="bullet">
                <item><description>
                 A. J. Smola and B. Schölkopf. A Tutorial on Support Vector Regression. NeuroCOLT2
                 Technical Report Series, 1998. Available on: <a href="http://www.kernel-machines.org/publications/SmoSch98c">
                 http://www.kernel-machines.org/publications/SmoSch98c </a></description></item>
                <item><description>
                 S.K. Shevade et al. Improvements to SMO Algorithm for SVM Regression, 1999. Available
                 on: <a href="http://drona.csa.iisc.ernet.in/~chiru/papers/ieee_smo_reg.ps.gz">
                 http://drona.csa.iisc.ernet.in/~chiru/papers/ieee_smo_reg.ps.gz </a></description></item>
                <item><description>
                 G. W. Flake, S. Lawrence. Efficient SVM Regression Training with SMO.
                 Available on: <a href="http://www.keerthis.com/smoreg_ieee_shevade_00.pdf">
                 http://www.keerthis.com/smoreg_ieee_Shevade_00.pdf </a></description></item>
              </list></para>
            </remarks>
            
            <example>
            <code>
            // Example regression problem. Suppose we are trying
            // to model the following equation: f(x, y) = 2x + y
            
            double[][] inputs = // (x, y)
            {
                new double[] { 0,  1 }, // 2*0 + 1 =  1
                new double[] { 4,  3 }, // 2*4 + 3 = 11
                new double[] { 8, -8 }, // 2*8 - 8 =  8
                new double[] { 2,  2 }, // 2*2 + 2 =  6
                new double[] { 6,  1 }, // 2*6 + 1 = 13
                new double[] { 5,  4 }, // 2*5 + 4 = 14
                new double[] { 9,  1 }, // 2*9 + 1 = 19
                new double[] { 1,  6 }, // 2*1 + 6 =  8
            };
            
            double[] outputs = // f(x, y)
            {
                    1, 11, 8, 6, 13, 14, 20, 8
            };
            
            // Create Kernel Support Vector Machine with a Polynomial Kernel of 2nd degree
            var machine = new KernelSupportVectorMachine(new Polynomial(2), inputs: 2);
            
            // Create the sequential minimal optimization teacher
            var learn = new SequentialMinimalOptimizationRegression(machine, inputs, outputs);
            
            // Run the learning algorithm
            double error = learn.Run();
            
            // Compute the answer for one particular example
            double fxy = machine.Compute(inputs[0]); // 1.0003849827673186
            </code>
            </example>
            
        </member>
        <member name="M:Accord.MachineLearning.VectorMachines.Learning.SequentialMinimalOptimizationRegression`2.Create(System.Int32,`0)">
            <summary>
            Creates an instance of the model to be learned. Inheritors
            of this abstract class must define this method so new models
            can be created from the training data.
            </summary>
        </member>
    </members>
</doc>
